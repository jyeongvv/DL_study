{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9BYjDBltEYwGMhtZAptxb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyeongvv/DL_study/blob/main/jyeongvv/0406_DL_LSTM_Seq2Seq_Transformer_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "Ef4VBI2fMTBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 게이트를 이용해 이전 은닉 상태를 현재의 입력에 반영하는 알고리즘(입력 시퀀스)\n",
        "* 장기 기억을 위한 `cell state` 를 추가한 모델(장기 의존성)\n",
        "* 3가지 게이트를 이용해 이전 시점의 은닉 상태를 현 시점에 반영(게이트 메커니즘)\n",
        "\n",
        "  > * 망각 게이트 : `cell state`에 저장된 과거 정보를 사용할 것인가에 대한 여부 결정\n",
        "  > * 입력 게이트 : `cell state`에 현재 정보를 덮어쓸 것인가 결정\n",
        "  > * 출력 게이트 : `cell state`와 현재 정보를 합쳐 현재의 은닉 상태를 결정\n",
        "* 주가, 날씨, 텍스트 ... 순서가 있는 데이터를 다룰 때 용이\n",
        "* 신경망 반복 사용이 필요한 곳에 사용 가능\n",
        "*셀 상태(cell state), 은닉 상태(hidden state)"
      ],
      "metadata": {
        "id": "VCSKUAj4MU-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "장점\n",
        "* RNN보다 성능 좋음\n",
        "\n",
        "단점\n",
        "* 입출력 관계 복잡\n",
        "* 과거의 정보가 흐려짐"
      ],
      "metadata": {
        "id": "0Z4UGLnNS1xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ZQTClSpvRloz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "cAc3qFtKTA8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glob** -> 파일을 패턴화해서 읽을 수 있게 도와주는 라이브러리"
      ],
      "metadata": {
        "id": "fXfGJYouTiGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* BOW (Bag of words - 모든 단어를 겹치지 않도록 고유한 번호로 나타낸 집합 = 단어 사전)\n",
        "* `return \"\".join(new_text).lower()` -> 소문자화\n",
        "  * 합쳐줄 구분자 **\" \"** 만들어주기\n",
        "* `all_headlines_df = all_headlines_df[all_headlines_df != 'N']` -> headlines에서 N만 빼주기"
      ],
      "metadata": {
        "id": "eLAUdGpITH7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋"
      ],
      "metadata": {
        "id": "YP9yyvxTToPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `if v not in string.punctuation:` -> 특수문자가 아닌 것만 남기기\n",
        "* corpus : 말뭉치\n",
        "* BOW : Bag of Words => 등장하는 모든 단어에 고유번호 지정"
      ],
      "metadata": {
        "id": "wxGDLzRQTrcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델"
      ],
      "metadata": {
        "id": "Lhc_FvsGUh2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 분류 (fc)\n",
        "* 정확도를 높이기 위한 분류기 한 더 사용(fc1, fc2)"
      ],
      "metadata": {
        "id": "G7PeYv_DUjCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "qz_V9WNfWlxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 문장 만들기 -> 2개 이상의 단어로 구성된 문장을 넣으면 => 다음 단어를 유추\n",
        "\n",
        "**학습**\n",
        "* `model.load_state_dict(torch.load(\"lstm.pt\", map_location=device))\n",
        "pred = generate(model, dataset.BOW)`\n",
        "  * ex) `pred = generate(model, dataset.BOW, 'red apple ')`"
      ],
      "metadata": {
        "id": "ukR28QcuWnpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "YV91Qt2cFt7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq"
      ],
      "metadata": {
        "id": "I6pXtoheFlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* LSTM을 인코더, 디코더로 구성해서 사용\n",
        "  * 인코더 : 번역하고자 하는 언어의 문장으로부터 정보를 추출\n",
        "  * 디코더 : 번역된 문장을 만든다다\n",
        "* 모델을 만들 떄 몇 개의 단어를 출력할지 모름\n",
        "* 문장을 입력 문장을 출력 -> Seq2Seq 구조 사용"
      ],
      "metadata": {
        "id": "YQEUl7cxFvE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 토큰 : 단어를 숫자로 표현\n",
        "* BOW, 임베딩층의 결과, 토큰은 다양하게 표현\n",
        "  * BOW를 그대로 사용 -> 희소 표현 벡터가 그 단어의 토큰이 됨\n",
        "  * BOW를 파이토치의 임베딩 층을 이용해서 밀집 표현으로 변환(단어의 토큰이 됨)"
      ],
      "metadata": {
        "id": "HkQyNSwKUW9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "장점\n",
        "* 순서가 있는 데이터를 다룰때 사용 가능\n",
        "* RNN, LSTM에 비해 성능이 좋음\n",
        "\n",
        "단점\n",
        "* 알고리즘 복잡 -> 구현 어려움\n",
        "* 일반적인 시계열 알고리즘보다 계산량 많음 -> 모든 시점을 고려해서.."
      ],
      "metadata": {
        "id": "HmhrT3tlQrZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 어텐션 메커니즘"
      ],
      "metadata": {
        "id": "FdughZTURSWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 디코더의 출력 벡터 = **어텐션 가중치**\n",
        "  * 입력 데이터 간의 유사도가 높을수록 해당 데이터의 어텐션 가중치가 높아짐\n",
        "  * 일반적으로 합이 1이 되도록 정규화 -> 입력 데이터 중에서 어느 하나에 집중하더라도 모든 입력 데이터를 동시에 고려할 수 있도록 하기 위함\n",
        "  * 자연어처리 분야에서 많이 쓰임\n",
        "* **어텐션 메커니즘**\n",
        "* \n",
        "  * 특정한 부분에 집중하여 그 부분의 정보를 활용하는 방식\n",
        "  > 1. 입력 데이터의 특성 추출: 입력 데이터를 특성 벡터로 변환\n",
        "\n",
        "   > 2. 쿼리(Query) 생성: 현재 처리 중인 입력 데이터를 나타내는 쿼리를 생성\n",
        "\n",
        "   > 3. 키(Key) 생성: 입력 데이터 중에서 주목할 만한 부분을 나타내는 키를 생성\n",
        "\n",
        "   > 4. 어텐션 스코어 계산: 쿼리와 각 키 간의 유사도를 계산\n",
        "\n",
        "   > 5. 소프트맥스(softmax) 함수 적용: 어텐션 스코어에 소프트맥스 함수를 적용하여 각 키의 어텐션 가중치를 계산\n",
        "\n",
        "   > 6. 가중합(Weighted sum): 각 키의 어텐션 가중치와 해당 입력 데이터의 특성 벡터를 곱하여 가중합을 계산\n",
        "\n",
        "   > 7. 출력(Output) 생성: 가중합 결과를 이용하여 최종 출력을 생성\n",
        "\n",
        "* 어텐션 메커니즘이 입력 데이터 중에서 특정한 부분에 집중하여 처리 -> 딥러닝 모델은 입력 데이터의 특정한 부분에 더욱 집중 / 보다 정확한 예측을 수행\n",
        "* 번역, 요약, 질의응답 등의 작업에서 좋은 성능을 보여줌."
      ],
      "metadata": {
        "id": "GgSN6MRJRWix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "YmMgFxKdSBgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 은닉 상태와 셀 상태를 합쳐서 LSTM을 더 간단하게 구현한 모델\n",
        "* GRU는 RNN의 hidden state를 업데이트하는 두 개의 gate를 사용 -> 업데이트 게이트, 리셋 게이트"
      ],
      "metadata": {
        "id": "lCL-ngFFWU9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* R에서 현 시점의 입력과 이전 시점의 은닉 상태를 입력받아 값을 출력한 후, 이전 시점의 은닉 상태와 곱해줌\n",
        "  * 이전의 정보 제거 가능\n",
        "  * 과거의 정보를 제거 할 수 있기에 **리셋 게이트**라고 부름\n",
        "  * 현 시점의 은닉 상태를 만들어 냄\n",
        "* 현재 입력값과 이전 hidden state를 고려하여, 얼마나 많은 정보를 유지할 것인지를 결정 -> **업데이트 게이트**\n",
        "  * 출력이 현시점의 은닉 상태 하나뿐임\n"
      ],
      "metadata": {
        "id": "1HBezOpaSENO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 어텐션 디코더"
      ],
      "metadata": {
        "id": "1n7J4I63WWNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 번역하고자 하는 문장의 특징을 추출하는 부분\n",
        "* 기계 번역, 이미지 캡셔닝, 음성 인식 등에서 활용\n",
        "* 임베딩층을 이용해 BOW를 밀집 표현으로 바꿔주고 GRU층의 입력으로 사용\n",
        "* 인코더 : 임베딩층, GRU층\n"
      ],
      "metadata": {
        "id": "2P1Kx_4aWXfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 어텐션 기계 번역기"
      ],
      "metadata": {
        "id": "fcqQsf-yXrxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 문장을 불러와 한 단어씩 인코더에 입력\n",
        "* 각 시점에서의 인코더의 결과를 저장\n",
        "* 디코더의 첫 입력으로 <SOS> 토큰을 입력해줌\n",
        "* 디코더의 첫 은닉 상태로 인코더의 마지막 은닉 상태를 입력\n",
        "* 디코더의 예측 단어와 은닉 상태를 다음 시점으로 넘겨줌\n",
        "* 오차 계산 및 역전파 진행"
      ],
      "metadata": {
        "id": "yvAxrNqgXunS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "PE4Y1Rw_FpAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "ZPyLRHLGFqA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aspe2hF1FwS1"
      }
    }
  ]
}