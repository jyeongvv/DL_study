{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZMgauhgPgTt3hKva9cHRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyeongvv/DL_study/blob/main/jyeongvv/0331_DNN%2C_CNN%2C_ResNet_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN"
      ],
      "metadata": {
        "id": "edU-UM53qLIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforms에서 자주 쓰이는 기능"
      ],
      "metadata": {
        "id": "CdR7RwBwqMjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ToTensor : 이미지를 파이토치 텐서로 변환\n",
        "* Resize : 이미지 크기 조정\n",
        "* Normalize : 주어진 평균과 표준편차를 이용하여 정규화\n",
        "* RandomHorizontalFlip : 무작위로 이미지의 오른쪽과 왼쪽을 뒤집는 기능\n",
        "* RandomCrop : 이미지를 무작위로 자르는 기능"
      ],
      "metadata": {
        "id": "exGO2Io5uzah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋\n",
        "* torchvision.datasets로 생성된 객체 -> 파이토치 내부 클래스 torch.utils.data.Dataset을 상속\n",
        "* 클래스에 넣어준 후 데이터 로딩 -> 사용 가능\n",
        "* 배치 크기(batch size)를 지정\n",
        "* iter() : 반복되는 객체를 반복문 안에 이용할 수 있도록 만들어주는 함수\n",
        "* next() : 배치 1개를 (아직 반복되지 않은 하나의 원소를) 불러와주는 함수\n",
        "* utils.make_grid() -> 여러 이미지를 모아서 하나의 이미지로\n",
        "* np.transpose -> 차원의 순서를 교체\n",
        "* 데이터셋에서는 이름 대신에 숫자 번호로 레이블이 주어짐 -> 딕셔너리화\n",
        "* 이미지의 데이터는 가로(픽셀수), 세로(픽셀수), 색상 3차원 행렬로 표현"
      ],
      "metadata": {
        "id": "HwMb15DXu5Vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인공신경망"
      ],
      "metadata": {
        "id": "PQ3FduUBIxvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* USE_CUDA\n",
        "* 배치사이즈와 에포크 설정해주기"
      ],
      "metadata": {
        "id": "PcQ5d93pI91R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 불러오기"
      ],
      "metadata": {
        "id": "BMUqqgM4JOnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ToTensor를 통해 이미지를 파이토치 Tensor화"
      ],
      "metadata": {
        "id": "y2vIrSxiJRdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 분류\n",
        "`image claasification`\n",
        "* 이미지 한장을 받아 이 이미지가 어느 클래스에 속해있는지 알려줌\n",
        "* 단순하지만 영향력 강한편\n",
        "* 비디오 분류 모델(연속된 이미지)도 기본적인 이미지 분류방식과 크게 다르지 않음"
      ],
      "metadata": {
        "id": "g0OCMwmfJgoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 분류를 위한 인공 신경망\n",
        "* 입력 x와 레이블(정답) y를 받아서 학습한 다음, 새로운 X가 왔을 때 어떤 패션 아이템인지 예측하는 모델"
      ],
      "metadata": {
        "id": "xn9c0WRgJ-WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 인공 신경망 구성\n",
        "```\n",
        " nn.Linear 클래스는 선형 결합을 수행하는 객체를 만듦\n",
        "        self.fc1 = nn.Linear(784, 256) # input 784, output 256\n",
        "        # 1 x 28 x 28 -> 784 픽셀값(한 점씩)을 입력 받아서 가중치를 행렬곱/편향. 값 256개를 출력\n",
        "        # fc는 fully connected -> 이전 레이어의 모든 노드가 다음 레이어의 모든 노드에 연결된 층 (Dense) \n",
        "        \n",
        "        self.fc2 = nn.Linear(256, 128) # input 256, output 128\n",
        "        self.fc3 = nn.Linear(128, 10) # input 128, output 10\n",
        "        # 출력값 10개 각각은 클래스가 될 확률을 나타내며, 10개 중 값이 가장 큰 클래스가 이 모델의 예측값의 될 것임\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "훈련 과정을 표현\n",
        "    def forward(self, x): # x는 입력되는 텐서(input_tensor)\n",
        "        # 데이터의 흐름을 정의\n",
        "        # n, 색상, 세로, 가로 ->  (-1, 784) # 64, 784 (배치 사이즈 만큼)\n",
        "        # 입력을 받아 view() 함수를 이용하여 랭크 1 텐서로 변환\n",
        "        x = x.view(-1, 784) # 28px x 28px인 이미지 텐서를 784 한 줄짜리 1차원 텐서\n",
        "        # -1 : 나머지값들. (배치 사이즈, 데이터 사이즈...)\n",
        "        \n",
        "        # fc1()과 fc2()를 거치게 할 것, 각각 층은 ReLU 활성화 함수를 통해서 처리\n",
        "        # F.relu == nn.ReLU (거의 동일, 취향 문제) -> 가중치가 없는 연산 (저장 X)\n",
        "        # nn.Linear -> 선형결합 (가중치) -> 거의 강제. (init(생성자)에 선언하는 것이 권장)\n",
        "        # x = self.fc1(x)\n",
        "        # x = F.relu(x)\n",
        "        x = F.relu(self.fc1(x)) # 입력층 - 은닉층1\n",
        "        x = F.relu(self.fc2(x)) # 입력층 - 은닉층2\n",
        "\n",
        "        # 마지막으로 fc3() 함수까지 거쳐 나온 값 10개\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "```"
      ],
      "metadata": {
        "id": "mKcbKwmgKIj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* to() 함수는 모델의 파라미터들을 지정한 장치의 메모리로 **보내는** 역할을 함\n",
        "\n",
        "최적화 알고리즘\n",
        "* 최적화 알고리즘\n",
        "  * 파이토치 내장 모듈인 optim.SGD를 사용\n",
        "  * SGD (확률적 경사하강법, stochastic gradient descent) : 모델 최적화를 확률적 경사하강법\n",
        "  * 모델 내부의 정보를 넘겨주는 model.parameters() 함수와 직접 설정한 학습률(lr)을 입력"
      ],
      "metadata": {
        "id": "2jqIeCJyLKez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "5oE_oDe3Lrs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* train : 학습할 model, 데이터를 공급해주는 train_loader, 최적화를 담당할 optimizer를 넣을 것\n",
        "* `model.train()` : 학습 모드 <-> `model.eval()` : 평가모드\n",
        "* enumerate(연속된 데이터) -> zip(인덱스, 값)\n",
        "* data : 모델에 입력할 data (이미지 텐서), target : 해당 이미지의 분류값. 클래스.\n",
        "* 모델의 가중치를 보낸 장치(DEVICE) -> 학습 데이터도 같은 장치로 보내야 함\n",
        "* 배치를 처리할 때마다 기울기를 새로 계산해줘야함 -> optimizer.zero_grad()\n",
        "* 학습 데이터에 대한 모델의 예측값을 output\n",
        "        `output = model(data)`\n",
        "* 이진 교차 엔트로피 binary cross entropy : 클래스가 2개 (분류해야하는 대상이 2개)\n",
        "  * 교차 엔트로피 cross entropy : 클래스가 3개 이상\n",
        "* `optimizer.step()` -> 계산한 기울기를 바탕으로 앞서 정의한 알고리즘에 맞추어 가중치를 수정"
      ],
      "metadata": {
        "id": "j6uVjdYyLyUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 일반화 `generalization` : 세상에 존재하는 모든 데이터에 최적화하는 것\n",
        "* 일반화 오류 `generalization error` : 학습 데이터를 기반으로 한 모델이 학습하지 않은 데이터에 얼마나 적응하는지를 수치로 나타낸 것\n",
        "    * 일반화 오류는 작을수록 좋음\n",
        "* 평가용 데이터셋 = 실제 세상의 모든 데이터를 대표함\n",
        "* 학습(7), 검증(2), 테스트(1) 3단계로 나뉨\n",
        "* **하이퍼 파라미터** : 모델 층의 종류와 크기, 배치 크기, 학습률 등 머신러닝 모델이 배우지 않고 사용자가 직접 지정해주는 값\n",
        "  * 모델의 가중치를 최적화하는데 영향을 줌\n",
        "  * 데이터 모으는 과정만큼 중요함"
      ],
      "metadata": {
        "id": "ZdLJO2OWM4eZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**학습**\n",
        "```\n",
        "# 평가 함수 evaluate\n",
        "# 모델의 일반화 정도 확인 + 학습을 언제 멈춰야할지 알아냄 (조기종료)\n",
        "def evaluate(model, test_loader): # 최적화 담당하는 optimizer 없어도 됌\n",
        "    # epoch가 끝날 때마다 테스트셋으로 모델의 성능을 측정\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    test_loss = 0 # 테스트셋의 오차\n",
        "    correct = 0 # 예측이 맞은 갯수를 담아줄 변수\n",
        "\n",
        "    # torch.no_grad() -> 생성 / with가 끝나면 해당 객체, 기능을 close.\n",
        "    with torch.no_grad(): # 기울기 계산 끄기\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE) # DEVICE로 데이터 보내기\n",
        "            output = model(data) # 테스트 데이터의 예측값\n",
        "\n",
        "            test_loss += F.cross_entropy(output, target,\n",
        "                                         reduction='sum').item() # item() 스칼라 텐서 안에 있는 숫자값을 파이썬의 숫자 자료형 형태로 뽑아주는 함수\n",
        "            # 평가를 위해서 교차 엔트로피를 거칠 때 reduction을 'sum'을 지정\n",
        "            # 원래 default는 mean(평균)\n",
        "            # 모든 오차를 더해줌\n",
        "            # ---\n",
        "            # 정확도\n",
        "            # 가장 큰 값을 가진 클래스가 모델의 \n",
        "            # -> output.max(1, ...)[1] -> 가장 높게 나온 확률을 가진 패션 아이템의 종류 (인덱스)를 추출하는 코드\n",
        "            # 예측과 정답을 비교하여서 일치할 경우 -> correct에 1을 더함 \n",
        "            # output.max() -> (가장 큰 값(0), 그 값이 있는 자리의 인덱스(1))\n",
        "            # print(output)\n",
        "            # https://pytorch.org/docs/stable/generated/torch.Tensor.max.html\n",
        "            pred = output.max(1, keepdim=True)[1] # max(차원)\n",
        "            # print(pred)\n",
        "\n",
        "            # 모델의 예측 패션 아이템과 레이블(정답)이 일치하는지는 eq (0, 1)\n",
        "            # print(pred.eq(target.view_as(pred)))\n",
        "            # target.view_as(pred) -> target을 pred의 모양으로 변경\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() # 일치하는 것만 -> 1, 0 -> count -> item() (스칼라)\n",
        "            # -> sum (모두 더하면 현 배치에서 모델을 맞춘 정답 개수 구함)\n",
        "            # view_as -> 인수로 들어간 텐서의 모양으로 바꿔줌(정렬)\n",
        "    # 배치별 총 오차와, 총 맞춘 개수를 합친 test_loss, correct\n",
        "\n",
        "    # test_loss : 전체 데이터셋에 대한 오차 -> 배치별로 나눠져 있는 것의 합\n",
        "    # correct : 맞힌 개수의 합\n",
        "    # 총 정답 평균 -> 100을 곱해서 정확도 (accuracy) 구하기\n",
        "    test_loss /= len(test_loader.dataset) # 평균오차\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset) # 얼마나 맞췄는지\n",
        "    return test_loss, test_accuracy\n",
        "```\n",
        "\n",
        "* 읽어보기 -> 어떻게 흘러가는지 아는게 중요(흐름)"
      ],
      "metadata": {
        "id": "Abv4f7O6QOK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 과적합 / dropout\n",
        "* 과적합 `overfitting`\n",
        "  * 학습 성능은 좋은데, 테스트셋이나 실제 상황에서는 성능이 안나옴\n",
        "  * 학습 데이터에만 치중되어 새로운 데이터에서는 성능이 잘 나오지 않는 상황\n",
        "* 과소적합 `underfitting`\n",
        "  * 학습을 제대로 진행하지 않은 상황\n",
        "  * 학습 데이터도 제대로 학습하지 않은 경우\n",
        "\n",
        "**바람직한 상태?** -> 과소적합과 과적합의 중간상태!\n",
        "* 일반화 = 학습데이터와 그렇지 않은 데이터(실제)에서 동시에 높은 성능을 내는 것\n",
        "* 분류형 -> 일반화를 지향함\n",
        "* 검증 오차가 올라가는 순간을 포착하여 학습을 종료하는 것을 **조기 종료**`early stopping`라고 함\n"
      ],
      "metadata": {
        "id": "hx-0tf3OQhnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 늘리기\n",
        "* data augmentation 적용\n",
        "* 이미지 데이터의 경우 -> 이미지의 일부분 자르기, 돌리기, 노이즈를 더하기, 색상 변경... 여러 방법 사용 가능\n",
        "\n",
        "drop out\n",
        "* 신경망의 일부를 사용하지 않는 방법 -> 모델에 직접 영향을 줌\n",
        "* 학습에서 배제된 뉴런 외에 다른 뉴런들에 가중치를 분산시키고 개별 뉴런이 특징에 고정되는 현상을 방지하는 기능 (영향력이 큰 몇몇 요소들을 의도적으로 배제)"
      ],
      "metadata": {
        "id": "kI98KJQiSGtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "fKZCH1bASsDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CNN은 컨볼루션, 폴링, 드롭아웃, 일반적인 신경망 계층의 조합으로 이루어짐"
      ],
      "metadata": {
        "id": "b-D5QWitSt_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 코드를 간결하게 하기 위해서 Fashion MNIST 데이터셋을 DataLoader를 부를 때 바로 정의\n",
        "* transfroms를 이용한 전처리 → 파이토치 텐서화, 정규화 진행\n",
        "   * 파이토치에서 CNN 구현 -> nn.Module 상속받기 / torchvision 패키지를 사용"
      ],
      "metadata": {
        "id": "9vP2imPRTfV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* nn.Conv2d 모듈 -> 입력 x를 받는 함수\n",
        "  * nn.Conv2d(입력 채널 수, 출력 채널 수)\n",
        "* self.conv1, self.conv2 -> CNN 모델의 내부 변수(속성)들은 함수로 취급\n",
        "* 필터(커널) 크기 = kernel_size로 지정 -> 숫자 하나만 지정하면 정사각형으로 간주\n",
        "*  x = F.max_pool2d(x, n) # 풀링도 커널사이즈가 있음 (nxn)\n",
        "* **활성화 함수 F.relu** 거치도록!!"
      ],
      "metadata": {
        "id": "tHZ0XYNWMLi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* fc -> 선형결합을 해서 한줄로 펴준 다음에 우리가 분류하기를 원하는 클래스 값만큼 특징을 다시 분류\n"
      ],
      "metadata": {
        "id": "OoinafZMNLNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `loss = F.cross_entropy(output, target)` -> 크로스 엔트로피 오차 함수로 오차값 계산\n",
        "* 예측값과 정답값 사이의 교차 엔트로피 -> 손실(에러) 계산\n",
        "*  `optimizer.step()` -> 모델의 학습 패러미터 갱신 / 가중치 (conv도 갱신, linear 갱신)\n",
        "* `loss.backward()` -> 오차역전파 -> 미분계수 전달\n",
        "* ` optimizer.zero_grad()` -> 배치 돌 때마다 기울기값(최적화) 리셋\n"
      ],
      "metadata": {
        "id": "t4BdrRKxNcJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "- DNN으로 구현했던 FashionMNIST를 CNN으로 개선\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, epoch)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    \n",
        "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))\n",
        "```"
      ],
      "metadata": {
        "id": "_rd4P0Z4N742"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhldR9BbOBnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1Xh0iIKLOIe5"
      }
    }
  ]
}